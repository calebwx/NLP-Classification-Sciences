{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from datetime import timezone\n",
    "import time\n",
    "import os\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://api.pushshift.io/reddit/search/submission'\n",
    "url_com = 'https://api.pushshift.io/reddit/search/comment'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function definitions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sub_df(sub_name, num_to_pull, start_utc = None, min_comments = 0, drop_removed = True):\n",
    "    #Returns a dataframe containing num_to_pull submissions from the specified subreddit\n",
    "    #Dataframe has ID, Title, selftext and num_comments\n",
    "    \n",
    "    post_count = 0    #Keeps track of how many posts have been pulled\n",
    "    data = []         #Holds all the data to create the DF after the while loop\n",
    "    \n",
    "    res_count = 0     #for debugging\n",
    "    \n",
    "    if start_utc == None:\n",
    "        start_utc = int(datetime.now(timezone.utc).timestamp()) #If the start timestamp isn't specified, use the current time\n",
    "        \n",
    "    min_comment_count = '>' + str(min_comments-1) #paramater to select only submissions with comments greater than the number specified\n",
    "    \n",
    "    timer = 0 \n",
    "    \n",
    "    while post_count < num_to_pull:\n",
    "        #To make sure to get the specific number pulled, check to see if the remaining count is less than 100, if not, just get 100\n",
    "        if (num_to_pull - post_count) < 100:\n",
    "            get_size = (num_to_pull - post_count)\n",
    "        else:\n",
    "            get_size = 100\n",
    "            \n",
    "        timer = time.time() #Timer to avoid 429 codes from making too many requests\n",
    "        \n",
    "        res = requests.get(url, params = {'subreddit' : sub_name, 'size' : get_size, 'before' : start_utc, 'num_comments' : min_comment_count})\n",
    "        res_count += 1\n",
    "        \n",
    "        clear_output(wait=True) #reference: https://stackoverflow.com/a/24818304\n",
    "        \n",
    "        print(f'{100 * post_count/num_to_pull}%')\n",
    "        \n",
    "        while time.time() < (timer + 1):\n",
    "            time.sleep(0.1)\n",
    "        \n",
    "        if res.status_code != 200:\n",
    "            print(f'Status Code: {res.status_code}')\n",
    "            print(res_count)\n",
    "            return None\n",
    "            \n",
    "        new_data = res.json()['data']\n",
    "            \n",
    "        data.extend(new_data)\n",
    "        \n",
    "        post_count += 100 #it's OK if this number goes over num_to_pull, so just add 100 every time\n",
    "        \n",
    "        if post_count < num_to_pull: #do not do this if we don't need to make more requests\n",
    "            try:\n",
    "                start_utc = new_data[-1]['created_utc'] #This is the starting point for grabbing more posts\n",
    "            except:\n",
    "                print(\"Failed to get UTC of last Post. Printing list element that caused failure.\")\n",
    "                try:\n",
    "                    print(new_data[-1])\n",
    "                except:\n",
    "                    print(\"Could not print element, returning end of working data.\")\n",
    "                    return data[-50:]\n",
    "    \n",
    "    print(res_count)\n",
    "    \n",
    "    df = pd.DataFrame(data)[['id', 'title', 'removed_by_category', 'created_utc', 'selftext','num_comments']]\n",
    "    df['subreddit'] = [sub_name for _ in range(len(df))] #Creates a new column with the subreddit name - eventually, the target for the model\n",
    "    \n",
    "    #Filter out submissions that have been removed. Could result in small samples for heavily moderated forums, so there is the option to keep them in.\n",
    "    if drop_removed:\n",
    "        df = df[df['removed_by_category'].isna()]\n",
    "        \n",
    "    df['created_utc'] = df['created_utc'].apply(datetime.fromtimestamp)\n",
    "    \n",
    "    return df[['id', 'title', 'selftext','num_comments', 'created_utc', 'subreddit']] #drop the removed category before returning the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to run the 'get_sub_df' function, but automatically check before re-downloading data, and save data as csv\n",
    "\n",
    "def get_titles_text(sub_name, number = 10_000):\n",
    "    #Step 1 is to see if the data exists already. We don't want to use the API if it isn't necesssary.\n",
    "    if sub_name + '_data.csv' in os.listdir('./data'):\n",
    "        print(\"That data ({sub_name}) is already in the data folder. Delete the file if you want to get the data again.\")\n",
    "        return None\n",
    "    else:\n",
    "        df = get_sub_df(sub_name, number)\n",
    "        df.to_csv('./data/' + sub_name + '_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.0%\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "get_titles_text('physics')\n",
    "get_titles_text('chemistry')\n",
    "get_titles_text('biology')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
